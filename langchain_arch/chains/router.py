import asyncio
import json
from typing import Dict, Any, AsyncIterator, Union

from langchain_core.tracers.log_stream import RunLogPatch

from .insight_workflow import InsightWorkflow
from .optimization_workflow import OptimizationWorkflow
from ..agents.classifier import ClassifierAgent
from ..utils.neo4j_utils import Neo4jDatabase

class Router:
    """
    Top-level router using astream_log.
    Classifies query and routes to the appropriate workflow,
    streaming RunLogPatch objects and custom status dicts.
    Gets final agent results via separate ainvoke calls after streaming.
    """
    def __init__(self, schema_file: str = "neo4j_schema.md"):
        # Initialize DB connection per Router instance.
        # Ensures connection is managed if Router is long-lived.
        self._db_connection = None
        self.schema_file = schema_file
        self.classifier = ClassifierAgent()
        # Workflow instantiation moved to run() to ensure they get the active DB connection

    def _get_db(self):
        """Creates or returns the active DB connection for this router instance."""
        if self._db_connection is None:
            # Add error handling for DB connection failure if needed
            self._db_connection = Neo4jDatabase()
        return self._db_connection

    def _close_db(self):
        """Closes the DB connection if it exists."""
        if self._db_connection:
            try:
                self._db_connection.close()
                # print("Router: DB connection closed.")
            except Exception as e:
                print(f"Router: Error closing DB: {e}")
            finally:
                self._db_connection = None

    async def run(self, user_query: str) -> AsyncIterator[Union[RunLogPatch, Dict[str, Any]]]:
        """
        Runs classification and the selected workflow, streaming RunLogPatch and status dicts.
        Manages Neo4j connection lifecycle for the run.
        """
        yield {"type": "status", "step": "start_router", "status": "in_progress", "details": "Initializing..."}

        classification_output = None
        db = self._get_db()

        try:
            # --- Step 1: Classify Query using ainvoke --- 
            yield {"type": "status", "step": "classify_query", "status": "in_progress", "details": "Classifying query..."}
            
            try:
                # Invoke directly to get final result
                classification_output = await self.classifier.chain.ainvoke({"query": user_query})
            except Exception as class_err:
                 yield {"type": "error", "step": "classify_query", "status": "failed", "message": f"Failed to get classification result: {class_err}"}
                 self._close_db()
                 return

            if not isinstance(classification_output, dict) or "workflow" not in classification_output:
                 yield {"type": "error", "step": "classify_query", "status": "failed", "message": f"Classifier returned invalid final output: {classification_output}"}
                 self._close_db()
                 return

            # Yield final classification result as a status message
            yield {"type": "status", "step": "classify_query", "status": "completed", **classification_output}
            # NOTE: Reasoning for classification itself is usually not needed/generated by this agent

            # --- Step 2: Route to Workflow --- 
            workflow_type = classification_output.get("workflow")
            yield {"type": "status", "step": "route_workflow", "status": "in_progress", "details": f"Routing to '{workflow_type}' workflow."}

            if workflow_type == "insight":
                insight_workflow = InsightWorkflow(db, self.schema_file)
                # The workflow's run method will now handle streaming its agents' logs
                # and yielding its own status/final dicts
                async for workflow_chunk in insight_workflow.run(user_query):
                    yield workflow_chunk
            elif workflow_type == "optimization":
                optimization_workflow = OptimizationWorkflow(db, self.schema_file)
                async for workflow_chunk in optimization_workflow.run(user_query):
                    yield workflow_chunk
            else:
                yield {"type": "error", "step": "route_workflow", "message": f"Unknown workflow type: {workflow_type}"}
                # No need to close DB here, finally block handles it
                return
            
            # Workflow completion status is now yielded by the workflow itself
            # yield {"type": "status", "step": "workflow_complete", "status": "completed", "details": f"'{workflow_type}' workflow finished."}

        except Exception as e:
             yield {"type": "error", "step": "router_exception", "message": f"Router Error: {e}"}
             import traceback
             traceback.print_exc()
        finally:
            self._close_db()
            # Yield final status AFTER closing DB is safer if needed, but generally not required
            # yield {"type": "status", "step": "end_router", "status": "finished"}

# Example usage (for testing)
if __name__ == '__main__':
    import os
    from dotenv import load_dotenv

    load_dotenv()

    async def main_test():
        schema_f = os.path.join(os.path.dirname(__file__), '../../neo4j_schema.md')
        print(f"Schema path: {schema_f}")

        router = Router(schema_file=schema_f)

        test_query_insight = "Which ad groups have the highest cost per click?"
        print(f"\n--- Running Router (RunLogPatch) with Insight Query: '{test_query_insight}' ---")
        try:
            async for result_chunk in router.run(user_query=test_query_insight):
                if isinstance(result_chunk, RunLogPatch):
                    # Basic print for RunLogPatch ops
                    print(f"PATCH: run_id={result_chunk.run_id} ops={result_chunk.ops}")
                elif isinstance(result_chunk, dict):
                    print(f"DICT: {json.dumps(result_chunk, indent=2)}")
                else:
                    print(f"OTHER: {result_chunk}")
        except Exception as e:
            print(f"Insight test failed: {e}")
            import traceback
            traceback.print_exc()

        # Create a new router instance for the second test to ensure clean DB handling
        router_opt = Router(schema_file=schema_f)
        test_query_optimization = "Suggest ways to lower my overall advertising spend."
        print(f"\n--- Running Router (RunLogPatch) with Optimization Query: '{test_query_optimization}' ---")
        try:
            async for result_chunk in router_opt.run(user_query=test_query_optimization):
                 if isinstance(result_chunk, RunLogPatch):
                     print(f"PATCH: run_id={result_chunk.run_id} ops={result_chunk.ops}")
                 elif isinstance(result_chunk, dict):
                     print(f"DICT: {json.dumps(result_chunk, indent=2)}")
                 else:
                     print(f"OTHER: {result_chunk}")
        except Exception as e:
            print(f"Optimization test failed: {e}")
            import traceback
            traceback.print_exc()

    asyncio.run(main_test())
